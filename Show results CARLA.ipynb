{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting the CARLA simulator images from videos and showing the crossing prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from torch import from_numpy\n",
    "from torch import cuda\n",
    "from torch import no_grad\n",
    "from torch import optim\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from Code.GNN import *\n",
    "from Code.SkeletonsDataset import *\n",
    "from Code.ModelTrainEvaluate import *\n",
    "\n",
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the skeletons dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = 'test'\n",
    "numberOfClasses = 2\n",
    "info = 2\n",
    "\n",
    "dataset = SkeletonsDataset('Data/CARLA/' + subset + '_preprocessed.csv', numberOfJoints=26,\n",
    "                           normalization='minmax', target='crossing', info=info, remove_undetected=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "videos_list = dataset.loadedData['video'].unique().tolist()\n",
    "\n",
    "videos_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.loadedData[['video','frame','skeleton','crossing']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First element of the dataset:\n",
    "t0 = dataset[0]\n",
    "\n",
    "# Node features:\n",
    "t1 = t0.x_temporal[0]\n",
    "\n",
    "# Number of nodes:\n",
    "numberOfNodes = t1.shape[0]\n",
    "\n",
    "# Number of dimensions of each node features:\n",
    "embed_dim = t1.shape[1]\n",
    "\n",
    "print('Number of nodes per skeleton:', numberOfNodes)\n",
    "print('Number of features per node:', embed_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SpatialTemporalGNN(embed_dim, numberOfClasses, numberOfNodes)\n",
    "\n",
    "#model_path = 'exportedModels/CARLA/Approach_2-3'\n",
    "model_path = 'exportedModels/CARLA/Full train dataset/SpatialTemporal - 5 frames/Epoch_199'\n",
    "model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the crossing/not-crossing prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, batch_size=500)\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "predictions, groundtruth = predict(model, loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the video and exporting the result as a GIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "quantity = 20\n",
    "\n",
    "gen_clips = os.listdir('Data/CARLA-videos/')\n",
    "\n",
    "videos_list_frames = dataset.loadedData['video'].tolist()\n",
    "\n",
    "exported = 0\n",
    "\n",
    "for video_id in videos_list:\n",
    "    \n",
    "    video_file_id = video_id.replace('clips/', '').replace('.mp4', '')\n",
    "    \n",
    "    if (video_file_id + '.mp4') not in gen_clips:\n",
    "        continue\n",
    "    \n",
    "    print('Starting processing of video', video_file_id)\n",
    "    \n",
    "    video = cv2.VideoCapture(\"Data/CARLA-videos/\" + video_file_id + \".mp4\")\n",
    "    \n",
    "\n",
    "    # First column in the dataset where the video starts:\n",
    "    video_first_dataset_row = videos_list_frames.index(video_id)\n",
    "\n",
    "\n",
    "    video_outputs = []\n",
    "\n",
    "    frame_i = 0\n",
    "    ret = True\n",
    "    while ret:\n",
    "\n",
    "        ret, frame = video.read()\n",
    "\n",
    "        if ret:\n",
    "\n",
    "            frame_prediction = int(predictions[video_first_dataset_row + frame_i])\n",
    "            frame_groundtruth = int(groundtruth[video_first_dataset_row + frame_i])\n",
    "\n",
    "            frame_prediction = \"Crossing\" if frame_prediction else \"Not-crossing\"\n",
    "            frame_groundtruth = \"Crossing\" if frame_groundtruth else \"Not-crossing\"\n",
    "\n",
    "            im_title = \"Prediction: \" + frame_prediction + \"\\nGroundtruth: \" + frame_groundtruth\n",
    "\n",
    "            try:\n",
    "                \n",
    "                fig = dataset.showSkeleton(videoNum=video_id, frameNum=frame_i, showLegend=False, frameImage=frame, \n",
    "                                           normalizedSkeletons=False, title=im_title, show=False, prediction=frame_prediction, groundtruth=frame_groundtruth)\n",
    "            \n",
    "                \n",
    "                canvas = FigureCanvasAgg(fig)\n",
    "                canvas.draw()\n",
    "                frame_result = np.asarray(canvas.buffer_rgba()).astype(np.uint8)\n",
    "\n",
    "                frame_result = Image.fromarray(frame_result)\n",
    "\n",
    "                video_outputs.append(frame_result)\n",
    "\n",
    "                canvas.get_renderer().clear()\n",
    "                plt.close(fig)\n",
    "\n",
    "                frame_i = frame_i + 1\n",
    "                                \n",
    "            except:\n",
    "                \n",
    "                ret = False\n",
    "\n",
    "    \n",
    "    # Export the prediction result as a GIF:\n",
    "    video_outputs[0].save(\"Videos_results/CARLA/\" + subset + \"/\" + video_file_id + \".gif\", save_all=True,\n",
    "                          append_images=video_outputs[1:], duration=30, loop=0)\n",
    "    \n",
    "    exported = exported + 1\n",
    "    \n",
    "    print('Exported video:', video_file_id, ' - Clip', str(exported) + '/' + str(quantity), '\\n')\n",
    "    \n",
    "    video.release()\n",
    "    \n",
    "    if exported == quantity:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c18793cfc07e61e6abd291769efaaa9a44374475e504c3592eba760dc613e5c8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('main')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
