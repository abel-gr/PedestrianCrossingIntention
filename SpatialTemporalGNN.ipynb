{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial-Temporal Graph Neural Network (Spatial-Temporal GNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction of the intention of pedestrians to cross the street or not, using Graph Neural Networks and the coordinates of their skeleton that was previously generated using Openpose in the JAAD dataset.\n",
    "\n",
    "**Input:** Pedestrian skeleton graph.\n",
    "\n",
    "**Output:** Binary classification (crossing or not crossing the street)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from torch import from_numpy\n",
    "from torch import cuda\n",
    "from torch import no_grad\n",
    "from torch import optim\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from Code.GNN import *\n",
    "from Code.SkeletonsDataset import *\n",
    "from Code.ModelTrainEvaluate import *\n",
    "from Code.MetricsPlots import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "info = 2\n",
    "\n",
    "train_dataset = SkeletonsDataset('Data/train_annotations_with_skeletons.csv',\n",
    "                                 normalization='minmax', target='cross', info=info)\n",
    "\n",
    "print('train_dataset len:', len(train_dataset))\n",
    "print('Temporal dimension length:', len(train_dataset.data[0].x_temporal))\n",
    "print('Shape of each skeletons data (x):', train_dataset.data[0].x_temporal[0].shape)\n",
    "\n",
    "train_dataset.loadedData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.loadedData[['video','frame','decision_point','skeleton','skeleton_detected','crossing']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of elements per class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "totalRows = len(train_dataset.loadedData)\n",
    "crossingRows = len(train_dataset.loadedData[train_dataset.loadedData['crossing']==1])\n",
    "nocrossingRows = len(train_dataset.loadedData[train_dataset.loadedData['crossing']!=1])\n",
    "\n",
    "print('Training dataset total rows:', totalRows)\n",
    "print('Training dataset crossing class samples:', crossingRows)\n",
    "print('Training dataset not-crossing class samples:', nocrossingRows)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.bar(1, crossingRows, label='Crossing class')\n",
    "plt.bar(0, nocrossingRows, label='Not-crossing class')\n",
    "plt.legend(loc='upper left', prop={'size': 15})\n",
    "plt.xticks([0, 1], size=15)\n",
    "plt.yticks(size=15)\n",
    "plt.xlabel('Class', size=15)\n",
    "plt.ylabel('Number of samples', size=15)\n",
    "plt.title('Dataset classes distribution', size=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Showing a skeleton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textsize = 14\n",
    "body_parts = train_dataset.body_parts\n",
    "pose_parts = train_dataset.pose_parts\n",
    "parts = list(body_parts.keys())\n",
    "\n",
    "node_coords = {}\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "skeleton = train_dataset.data[100].x_temporal[0][:, 0:2].tolist()\n",
    "\n",
    "for e, sk in enumerate(skeleton):    \n",
    "    node_coords[parts[e]] = sk\n",
    "    \n",
    "    plt.scatter(sk[0], sk[1], label=parts[e])\n",
    "\n",
    "for edge in pose_parts:\n",
    "    e0 = node_coords[edge[0]]\n",
    "    e1 = node_coords[edge[1]]\n",
    "    \n",
    "    plt.plot([e0[0], e1[0]], [e0[1], e1[1]], color='gray')\n",
    "\n",
    "plt.legend(loc='best', prop={'size': 11})\n",
    "plt.xticks(size=textsize)\n",
    "plt.yticks(size=textsize)\n",
    "plt.title('Skeleton preview in 2D', size=textsize)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = SkeletonsDataset('Data/val_annotations_with_skeletons.csv', normalization='minmax',\n",
    "                               target='cross', info=info)\n",
    "\n",
    "val_dataset.shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('val_dataset len:', len(val_dataset))\n",
    "print('Temporal dimension length:', len(val_dataset.data[0].x_temporal))\n",
    "print('Shape of each skeletons data (x):', val_dataset.data[0].x_temporal[0].shape)\n",
    "\n",
    "val_dataset.loadedData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset.loadedData[['video','frame','decision_point','skeleton','skeleton_detected','crossing']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of elements per class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalRows = len(val_dataset.loadedData)\n",
    "crossingRows = len(val_dataset.loadedData[val_dataset.loadedData['crossing']==1])\n",
    "nocrossingRows = len(val_dataset.loadedData[val_dataset.loadedData['crossing']!=1])\n",
    "\n",
    "print('Validation dataset total rows:', totalRows)\n",
    "print('Validation dataset crossing class samples:', crossingRows)\n",
    "print('Validation dataset not-crossing class samples:', nocrossingRows)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.bar(1, crossingRows, label='Crossing class')\n",
    "plt.bar(0, nocrossingRows, label='Not-crossing class')\n",
    "plt.legend(loc='upper left', prop={'size': 15})\n",
    "plt.xticks([0, 1], size=15)\n",
    "plt.yticks(size=15)\n",
    "plt.xlabel('Class', size=15)\n",
    "plt.ylabel('Number of samples', size=15)\n",
    "plt.title('Dataset classes distribution', size=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the classes of the two datasets are unbalanced, we cannot rely only on accuracy as our metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Showing a skeleton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textsize = 14\n",
    "body_parts = val_dataset.body_parts\n",
    "pose_parts = val_dataset.pose_parts\n",
    "parts = list(body_parts.keys())\n",
    "\n",
    "node_coords = {}\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "skeleton = val_dataset.data[0].x_temporal[0][:, 0:2].tolist()\n",
    "\n",
    "for e, sk in enumerate(skeleton):    \n",
    "    node_coords[parts[e]] = sk\n",
    "    \n",
    "    plt.scatter(sk[0], sk[1], label=parts[e])\n",
    "\n",
    "for edge in pose_parts:\n",
    "    e0 = node_coords[edge[0]]\n",
    "    e1 = node_coords[edge[1]]\n",
    "    \n",
    "    plt.plot([e0[0], e1[0]], [e0[1], e1[1]], color='gray')\n",
    "\n",
    "plt.legend(loc='best', prop={'size': 11})\n",
    "plt.xticks(size=textsize)\n",
    "plt.yticks(size=textsize)\n",
    "plt.title('Skeleton preview in 2D', size=textsize)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfClasses = 2\n",
    "\n",
    "y = train_dataset.loadedData['crossing'].to_numpy()\n",
    "y = np.where(y==1, 1, 0)\n",
    "bc = np.bincount(y)\n",
    "\n",
    "class_weights = len(train_dataset.loadedData) / (numberOfClasses * bc)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "\n",
    "print('class_weights:', class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First element of training subset:\n",
    "t0 = train_dataset[0]\n",
    "\n",
    "# Node features:\n",
    "t1 = t0.x_temporal[0]\n",
    "\n",
    "# Number of nodes:\n",
    "numberOfNodes = t1.shape[0]\n",
    "\n",
    "# Number of dimensions of each node features:\n",
    "embed_dim = t1.shape[1]\n",
    "\n",
    "print('Number of nodes per skeleton:', numberOfNodes)\n",
    "print('Number of features per node:', embed_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_epochs = 25\n",
    "batch_size = 500\n",
    "\n",
    "device = torch.device('cpu')\n",
    "model = SpatialTemporalGNN(embed_dim, numberOfClasses, numberOfNodes, net='GConvGRU', filterSize=3).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "crit = torch.nn.BCELoss()#weight=class_weights)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "loss_values = []\n",
    "\n",
    "metrics_train = []\n",
    "metrics_val = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    train_loss = train(model, train_loader, device, optimizer, crit)\n",
    "    loss_values.append(train_loss)\n",
    "\n",
    "    train_metrics = evaluate(model, train_loader, device, computed_loss=train_loss)\n",
    "    val_metrics = evaluate(model, val_loader, device, loss_crit=crit)\n",
    "\n",
    "    metrics_train.append(train_metrics)\n",
    "    metrics_val.append(val_metrics)\n",
    "    \n",
    "    if num_epochs <= 25:\n",
    "        \n",
    "        print_evaluation_train_val(epoch, train_metrics, val_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model performance plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(num_epochs, loss_values, figsize=10, textsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_classification_metrics_train_val(num_epochs, metrics_train, metrics_val, figsize=10, textsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fpr, tpr, roc_auc = ROC(model, train_loader, device, numberOfClasses)\n",
    "\n",
    "for plotclass in range(0, numberOfClasses):\n",
    "    plot_ROC(plotclass, fpr, tpr, roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fpr, tpr, roc_auc = ROC(model, val_loader, device, numberOfClasses)\n",
    "\n",
    "for plotclass in range(0, numberOfClasses):\n",
    "    plot_ROC(plotclass, fpr, tpr, roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = SkeletonsDataset('Data/test_annotations_with_skeletons.csv', normalization='minmax',\n",
    "                               target='cross', info=info)\n",
    "\n",
    "test_dataset.shuffle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of elements per class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalRows = len(test_dataset.loadedData)\n",
    "crossingRows = len(test_dataset.loadedData[test_dataset.loadedData['cross']=='crossing'])\n",
    "nocrossingRows = len(test_dataset.loadedData[test_dataset.loadedData['cross']=='not-crossing'])\n",
    "\n",
    "print('Test dataset total rows:', totalRows)\n",
    "print('Test dataset crossing class samples:', crossingRows)\n",
    "print('Test dataset not-crossing class samples:', nocrossingRows)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.bar(1, crossingRows, label='Crossing class')\n",
    "plt.bar(0, nocrossingRows, label='Not-crossing class')\n",
    "plt.legend(loc='best', prop={'size': 15})\n",
    "plt.xticks([0, 1], size=15)\n",
    "plt.yticks(size=15)\n",
    "plt.xlabel('Class', size=15)\n",
    "plt.ylabel('Number of samples', size=15)\n",
    "plt.title('Dataset classes distribution', size=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "test_metrics = evaluate(model, test_loader, device)\n",
    "\n",
    "\n",
    "print_evaluation_test(test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
