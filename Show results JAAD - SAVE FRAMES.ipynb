{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting the JAAD images from videos and showing the crossing prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from torch import from_numpy\n",
    "from torch import cuda\n",
    "from torch import no_grad\n",
    "from torch import optim\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from Code.GNN import *\n",
    "from Code.SkeletonsDataset import *\n",
    "from Code.ModelTrainEvaluate import *\n",
    "\n",
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the skeletons dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetName = 'JAAD'\n",
    "subset = 'test'\n",
    "poseEstimator = 'AlphaPose'\n",
    "numberOfClasses = 2\n",
    "info = 87\n",
    "data_augm = ''\n",
    "\n",
    "net = 'TGCN'\n",
    "dropout = 0.5\n",
    "num_epochs = 1000\n",
    "batch_size = 10000\n",
    "\n",
    "data_augmentation_name = '' if data_augm == None or data_augm == '' else '_' + data_augm\n",
    "numberOfJoints = 25 if poseEstimator == 'OpenPose' else 18\n",
    "\n",
    "dataset = SkeletonsDataset('Data/' + datasetName + '/' + subset + '_jaad_' + poseEstimator + '.csv',\n",
    "                           normalization='minmax', target='cross', info=info,\n",
    "                           remove_undetected=True, numberOfJoints=numberOfJoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_list = dataset.loadedData['video'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes per skeleton: 18\n",
      "Number of features per node: 3\n"
     ]
    }
   ],
   "source": [
    "# First element of the dataset:\n",
    "t0 = dataset[0]\n",
    "\n",
    "# Node features:\n",
    "t1 = t0.x_temporal[0]\n",
    "\n",
    "# Number of nodes:\n",
    "numberOfNodes = t1.shape[0]\n",
    "\n",
    "# Number of dimensions of each node features:\n",
    "embed_dim = t1.shape[1]\n",
    "\n",
    "print('Number of nodes per skeleton:', numberOfNodes)\n",
    "print('Number of features per node:', embed_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: TGCN_AlphaPose_info=87_dropout=0.5_epoch=1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelName = net + '_' + poseEstimator + '_info=' + str(info) + '_dropout=' + str(dropout) + data_augmentation_name\n",
    "modelName = modelName + '_epoch=' + str(num_epochs)\n",
    "\n",
    "print('Loading model:', modelName)\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "model = SpatialTemporalGNN(embed_dim, numberOfClasses, numberOfNodes, net=net,\n",
    "                           filterSize=embed_dim, dropout=dropout, batchSize=batch_size).to(device)\n",
    "\n",
    "model.load_state_dict(torch.load('exportedModels/' + datasetName + '/' + modelName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "predictions, groundtruth = predict(model, loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"Frames_results/\" + datasetName + '/' + poseEstimator + \"/\" + subset + \"/\" + modelName, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the crossing/not-crossing prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetName = 'JAAD'\n",
    "subset = 'test'\n",
    "poseEstimator = 'AlphaPose'\n",
    "numberOfClasses = 2\n",
    "info = 87\n",
    "data_augm = 'dataAugmentation4'\n",
    "\n",
    "net = 'TGCN'\n",
    "dropout = 0.5\n",
    "num_epochs = 1000\n",
    "batch_size = 10000\n",
    "\n",
    "data_augmentation_name = '' if data_augm == None or data_augm == '' else '_' + data_augm\n",
    "numberOfJoints = 25 if poseEstimator == 'OpenPose' else 18\n",
    "\n",
    "dataset2 = SkeletonsDataset('Data/' + datasetName + '/' + subset + '_jaad_' + poseEstimator + '.csv',\n",
    "                           normalization='minmax', target='cross', info=info,\n",
    "                           remove_undetected=True, numberOfJoints=numberOfJoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: TGCN_AlphaPose_info=87_dropout=0.5_dataAugmentation4_epoch=1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelName = net + '_' + poseEstimator + '_info=' + str(info) + '_dropout=' + str(dropout) + data_augmentation_name\n",
    "modelName = modelName + '_epoch=' + str(num_epochs)\n",
    "\n",
    "print('Loading model:', modelName)\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "model2 = SpatialTemporalGNN(embed_dim, numberOfClasses, numberOfNodes, net=net,\n",
    "                           filterSize=embed_dim, dropout=dropout, batchSize=batch_size).to(device)\n",
    "\n",
    "model2.load_state_dict(torch.load('exportedModels/' + datasetName + '/' + modelName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader2 = DataLoader(dataset2, batch_size=batch_size)\n",
    "\n",
    "predictions2, groundtruth2 = predict(model2, loader2, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"Frames_results/\" + datasetName + '/' + poseEstimator + \"/\" + subset + \"/\" + modelName, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the video and exporting the result as a GIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2873,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = np.argwhere(np.array(predictions)!=np.array(predictions2)).flatten()\n",
    "\n",
    "diff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1447,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = np.argwhere((np.array(predictions)!=np.array(predictions2)) & (np.array(predictions2)==np.array(groundtruth2))).flatten()\n",
    "\n",
    "diff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>frame</th>\n",
       "      <th>ped_id</th>\n",
       "      <th>skeleton</th>\n",
       "      <th>skeleton_detected</th>\n",
       "      <th>cross</th>\n",
       "      <th>reaction</th>\n",
       "      <th>hand_gesture</th>\n",
       "      <th>look</th>\n",
       "      <th>action</th>\n",
       "      <th>nod</th>\n",
       "      <th>occlusion</th>\n",
       "      <th>bbox</th>\n",
       "      <th>bbox_center_x</th>\n",
       "      <th>bbox_center_y</th>\n",
       "      <th>skeleton_center_x</th>\n",
       "      <th>skeleton_center_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>video_0005</td>\n",
       "      <td>29</td>\n",
       "      <td>0_5_19b</td>\n",
       "      <td>[[976.7589721679688, 700.0393676757812, 0.9337...</td>\n",
       "      <td>True</td>\n",
       "      <td>not-crossing</td>\n",
       "      <td>__undefined__</td>\n",
       "      <td>__undefined__</td>\n",
       "      <td>looking</td>\n",
       "      <td>walking</td>\n",
       "      <td>__undefined__</td>\n",
       "      <td>none</td>\n",
       "      <td>[949.0, 686.0, 1014.0, 821.0]</td>\n",
       "      <td>981.5</td>\n",
       "      <td>753.5</td>\n",
       "      <td>979.420281</td>\n",
       "      <td>735.037727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>video_0005</td>\n",
       "      <td>30</td>\n",
       "      <td>0_5_19b</td>\n",
       "      <td>[[976.5730590820312, 699.3145141601562, 0.9294...</td>\n",
       "      <td>True</td>\n",
       "      <td>not-crossing</td>\n",
       "      <td>__undefined__</td>\n",
       "      <td>__undefined__</td>\n",
       "      <td>looking</td>\n",
       "      <td>walking</td>\n",
       "      <td>__undefined__</td>\n",
       "      <td>none</td>\n",
       "      <td>[948.0, 685.0, 1013.0, 820.0]</td>\n",
       "      <td>980.5</td>\n",
       "      <td>752.5</td>\n",
       "      <td>979.039608</td>\n",
       "      <td>734.817508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>video_0005</td>\n",
       "      <td>31</td>\n",
       "      <td>0_5_19b</td>\n",
       "      <td>[[975.1636352539062, 698.6183471679688, 0.9457...</td>\n",
       "      <td>True</td>\n",
       "      <td>not-crossing</td>\n",
       "      <td>__undefined__</td>\n",
       "      <td>__undefined__</td>\n",
       "      <td>looking</td>\n",
       "      <td>walking</td>\n",
       "      <td>__undefined__</td>\n",
       "      <td>none</td>\n",
       "      <td>[947.0, 685.0, 1012.0, 821.0]</td>\n",
       "      <td>979.5</td>\n",
       "      <td>753.0</td>\n",
       "      <td>977.963189</td>\n",
       "      <td>734.422947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>video_0005</td>\n",
       "      <td>32</td>\n",
       "      <td>0_5_19b</td>\n",
       "      <td>[[974.7236328125, 698.50439453125, 0.960399389...</td>\n",
       "      <td>True</td>\n",
       "      <td>not-crossing</td>\n",
       "      <td>__undefined__</td>\n",
       "      <td>__undefined__</td>\n",
       "      <td>looking</td>\n",
       "      <td>walking</td>\n",
       "      <td>__undefined__</td>\n",
       "      <td>none</td>\n",
       "      <td>[946.0, 685.0, 1012.0, 822.0]</td>\n",
       "      <td>979.0</td>\n",
       "      <td>753.5</td>\n",
       "      <td>977.089771</td>\n",
       "      <td>733.959215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>video_0005</td>\n",
       "      <td>60</td>\n",
       "      <td>0_5_19b</td>\n",
       "      <td>[[948.6123657226562, 702.7825927734375, 0.9550...</td>\n",
       "      <td>True</td>\n",
       "      <td>not-crossing</td>\n",
       "      <td>__undefined__</td>\n",
       "      <td>__undefined__</td>\n",
       "      <td>looking</td>\n",
       "      <td>walking</td>\n",
       "      <td>__undefined__</td>\n",
       "      <td>none</td>\n",
       "      <td>[917.0, 682.0, 992.0, 840.0]</td>\n",
       "      <td>954.5</td>\n",
       "      <td>761.0</td>\n",
       "      <td>953.401199</td>\n",
       "      <td>743.422039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29904</th>\n",
       "      <td>video_0221</td>\n",
       "      <td>234</td>\n",
       "      <td>0_221_1623b</td>\n",
       "      <td>[[1231.2386474609375, 481.4247741699219, 0.847...</td>\n",
       "      <td>True</td>\n",
       "      <td>not-crossing</td>\n",
       "      <td>__undefined__</td>\n",
       "      <td>__undefined__</td>\n",
       "      <td>not-looking</td>\n",
       "      <td>walking</td>\n",
       "      <td>__undefined__</td>\n",
       "      <td>none</td>\n",
       "      <td>[1173.0, 452.0, 1293.0, 688.0]</td>\n",
       "      <td>1233.0</td>\n",
       "      <td>570.0</td>\n",
       "      <td>1226.064541</td>\n",
       "      <td>542.478532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29907</th>\n",
       "      <td>video_0221</td>\n",
       "      <td>237</td>\n",
       "      <td>0_221_1623b</td>\n",
       "      <td>[[1228.7847900390625, 482.3612976074219, 0.519...</td>\n",
       "      <td>True</td>\n",
       "      <td>not-crossing</td>\n",
       "      <td>__undefined__</td>\n",
       "      <td>__undefined__</td>\n",
       "      <td>not-looking</td>\n",
       "      <td>walking</td>\n",
       "      <td>__undefined__</td>\n",
       "      <td>none</td>\n",
       "      <td>[1173.0, 452.0, 1290.0, 682.0]</td>\n",
       "      <td>1231.5</td>\n",
       "      <td>567.0</td>\n",
       "      <td>1223.565582</td>\n",
       "      <td>541.724231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29908</th>\n",
       "      <td>video_0221</td>\n",
       "      <td>238</td>\n",
       "      <td>0_221_1623b</td>\n",
       "      <td>[[1228.268310546875, 481.5972900390625, 0.5759...</td>\n",
       "      <td>True</td>\n",
       "      <td>not-crossing</td>\n",
       "      <td>__undefined__</td>\n",
       "      <td>__undefined__</td>\n",
       "      <td>not-looking</td>\n",
       "      <td>walking</td>\n",
       "      <td>__undefined__</td>\n",
       "      <td>none</td>\n",
       "      <td>[1173.0, 452.0, 1289.0, 680.0]</td>\n",
       "      <td>1231.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>1223.872033</td>\n",
       "      <td>540.489577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29909</th>\n",
       "      <td>video_0221</td>\n",
       "      <td>239</td>\n",
       "      <td>0_221_1623b</td>\n",
       "      <td>[[1222.3924560546875, 473.7130126953125, 0.689...</td>\n",
       "      <td>True</td>\n",
       "      <td>not-crossing</td>\n",
       "      <td>__undefined__</td>\n",
       "      <td>__undefined__</td>\n",
       "      <td>not-looking</td>\n",
       "      <td>walking</td>\n",
       "      <td>__undefined__</td>\n",
       "      <td>none</td>\n",
       "      <td>[1173.0, 451.0, 1288.0, 676.0]</td>\n",
       "      <td>1230.5</td>\n",
       "      <td>563.5</td>\n",
       "      <td>1221.364712</td>\n",
       "      <td>538.148085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29916</th>\n",
       "      <td>video_0221</td>\n",
       "      <td>246</td>\n",
       "      <td>0_221_1623b</td>\n",
       "      <td>[[1206.43408203125, 490.98455810546875, 0.6079...</td>\n",
       "      <td>True</td>\n",
       "      <td>not-crossing</td>\n",
       "      <td>__undefined__</td>\n",
       "      <td>__undefined__</td>\n",
       "      <td>not-looking</td>\n",
       "      <td>walking</td>\n",
       "      <td>__undefined__</td>\n",
       "      <td>part</td>\n",
       "      <td>[1169.0, 450.0, 1276.0, 689.0]</td>\n",
       "      <td>1222.5</td>\n",
       "      <td>569.5</td>\n",
       "      <td>1215.559109</td>\n",
       "      <td>538.873359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1447 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            video  frame       ped_id  \\\n",
       "29     video_0005     29      0_5_19b   \n",
       "30     video_0005     30      0_5_19b   \n",
       "31     video_0005     31      0_5_19b   \n",
       "32     video_0005     32      0_5_19b   \n",
       "60     video_0005     60      0_5_19b   \n",
       "...           ...    ...          ...   \n",
       "29904  video_0221    234  0_221_1623b   \n",
       "29907  video_0221    237  0_221_1623b   \n",
       "29908  video_0221    238  0_221_1623b   \n",
       "29909  video_0221    239  0_221_1623b   \n",
       "29916  video_0221    246  0_221_1623b   \n",
       "\n",
       "                                                skeleton  skeleton_detected  \\\n",
       "29     [[976.7589721679688, 700.0393676757812, 0.9337...               True   \n",
       "30     [[976.5730590820312, 699.3145141601562, 0.9294...               True   \n",
       "31     [[975.1636352539062, 698.6183471679688, 0.9457...               True   \n",
       "32     [[974.7236328125, 698.50439453125, 0.960399389...               True   \n",
       "60     [[948.6123657226562, 702.7825927734375, 0.9550...               True   \n",
       "...                                                  ...                ...   \n",
       "29904  [[1231.2386474609375, 481.4247741699219, 0.847...               True   \n",
       "29907  [[1228.7847900390625, 482.3612976074219, 0.519...               True   \n",
       "29908  [[1228.268310546875, 481.5972900390625, 0.5759...               True   \n",
       "29909  [[1222.3924560546875, 473.7130126953125, 0.689...               True   \n",
       "29916  [[1206.43408203125, 490.98455810546875, 0.6079...               True   \n",
       "\n",
       "              cross       reaction   hand_gesture         look   action  \\\n",
       "29     not-crossing  __undefined__  __undefined__      looking  walking   \n",
       "30     not-crossing  __undefined__  __undefined__      looking  walking   \n",
       "31     not-crossing  __undefined__  __undefined__      looking  walking   \n",
       "32     not-crossing  __undefined__  __undefined__      looking  walking   \n",
       "60     not-crossing  __undefined__  __undefined__      looking  walking   \n",
       "...             ...            ...            ...          ...      ...   \n",
       "29904  not-crossing  __undefined__  __undefined__  not-looking  walking   \n",
       "29907  not-crossing  __undefined__  __undefined__  not-looking  walking   \n",
       "29908  not-crossing  __undefined__  __undefined__  not-looking  walking   \n",
       "29909  not-crossing  __undefined__  __undefined__  not-looking  walking   \n",
       "29916  not-crossing  __undefined__  __undefined__  not-looking  walking   \n",
       "\n",
       "                 nod occlusion                            bbox  bbox_center_x  \\\n",
       "29     __undefined__      none   [949.0, 686.0, 1014.0, 821.0]          981.5   \n",
       "30     __undefined__      none   [948.0, 685.0, 1013.0, 820.0]          980.5   \n",
       "31     __undefined__      none   [947.0, 685.0, 1012.0, 821.0]          979.5   \n",
       "32     __undefined__      none   [946.0, 685.0, 1012.0, 822.0]          979.0   \n",
       "60     __undefined__      none    [917.0, 682.0, 992.0, 840.0]          954.5   \n",
       "...              ...       ...                             ...            ...   \n",
       "29904  __undefined__      none  [1173.0, 452.0, 1293.0, 688.0]         1233.0   \n",
       "29907  __undefined__      none  [1173.0, 452.0, 1290.0, 682.0]         1231.5   \n",
       "29908  __undefined__      none  [1173.0, 452.0, 1289.0, 680.0]         1231.0   \n",
       "29909  __undefined__      none  [1173.0, 451.0, 1288.0, 676.0]         1230.5   \n",
       "29916  __undefined__      part  [1169.0, 450.0, 1276.0, 689.0]         1222.5   \n",
       "\n",
       "       bbox_center_y  skeleton_center_x  skeleton_center_y  \n",
       "29             753.5         979.420281         735.037727  \n",
       "30             752.5         979.039608         734.817508  \n",
       "31             753.0         977.963189         734.422947  \n",
       "32             753.5         977.089771         733.959215  \n",
       "60             761.0         953.401199         743.422039  \n",
       "...              ...                ...                ...  \n",
       "29904          570.0        1226.064541         542.478532  \n",
       "29907          567.0        1223.565582         541.724231  \n",
       "29908          566.0        1223.872033         540.489577  \n",
       "29909          563.5        1221.364712         538.148085  \n",
       "29916          569.5        1215.559109         538.873359  \n",
       "\n",
       "[1447 rows x 17 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.loadedData.iloc[diff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['video_0005',\n",
       " 'video_0016',\n",
       " 'video_0017',\n",
       " 'video_0028',\n",
       " 'video_0042',\n",
       " 'video_0045',\n",
       " 'video_0046',\n",
       " 'video_0048',\n",
       " 'video_0053',\n",
       " 'video_0055',\n",
       " 'video_0059',\n",
       " 'video_0071',\n",
       " 'video_0076',\n",
       " 'video_0084',\n",
       " 'video_0087',\n",
       " 'video_0090',\n",
       " 'video_0092',\n",
       " 'video_0093',\n",
       " 'video_0096',\n",
       " 'video_0097',\n",
       " 'video_0100',\n",
       " 'video_0103',\n",
       " 'video_0104',\n",
       " 'video_0105',\n",
       " 'video_0106',\n",
       " 'video_0107',\n",
       " 'video_0110',\n",
       " 'video_0113',\n",
       " 'video_0115',\n",
       " 'video_0116',\n",
       " 'video_0117',\n",
       " 'video_0124',\n",
       " 'video_0125',\n",
       " 'video_0128',\n",
       " 'video_0135',\n",
       " 'video_0141',\n",
       " 'video_0144',\n",
       " 'video_0148',\n",
       " 'video_0150',\n",
       " 'video_0151',\n",
       " 'video_0152',\n",
       " 'video_0155',\n",
       " 'video_0162',\n",
       " 'video_0163',\n",
       " 'video_0164',\n",
       " 'video_0165',\n",
       " 'video_0173',\n",
       " 'video_0177',\n",
       " 'video_0178',\n",
       " 'video_0179',\n",
       " 'video_0183',\n",
       " 'video_0187',\n",
       " 'video_0197',\n",
       " 'video_0201',\n",
       " 'video_0203',\n",
       " 'video_0206',\n",
       " 'video_0212',\n",
       " 'video_0213',\n",
       " 'video_0216',\n",
       " 'video_0221']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos_list = dataset.loadedData.iloc[diff]['video'].unique().tolist()\n",
    "\n",
    "videos_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting processing of video video_0005\n",
      "Exported video: video_0005  - Clip 1/10 \n",
      "\n",
      "Starting processing of video video_0016\n",
      "Exported video: video_0016  - Clip 2/10 \n",
      "\n",
      "Starting processing of video video_0017\n",
      "Exported video: video_0017  - Clip 3/10 \n",
      "\n",
      "Starting processing of video video_0028\n",
      "Exported video: video_0028  - Clip 4/10 \n",
      "\n",
      "Starting processing of video video_0042\n",
      "Exported video: video_0042  - Clip 5/10 \n",
      "\n",
      "Starting processing of video video_0045\n",
      "Exported video: video_0045  - Clip 6/10 \n",
      "\n",
      "Starting processing of video video_0046\n",
      "Exported video: video_0046  - Clip 7/10 \n",
      "\n",
      "Starting processing of video video_0048\n",
      "Exported video: video_0048  - Clip 8/10 \n",
      "\n",
      "Starting processing of video video_0053\n",
      "Exported video: video_0053  - Clip 9/10 \n",
      "\n",
      "Starting processing of video video_0055\n",
      "Exported video: video_0055  - Clip 10/10 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "quantity = 10\n",
    "\n",
    "gen_clips = os.listdir(\"Data/\" + datasetName + \"-videos/\")\n",
    "\n",
    "videos_list_frames = dataset.loadedData['video'].tolist()\n",
    "\n",
    "exported = 0\n",
    "\n",
    "for video_id in videos_list[0:10]:\n",
    "    \n",
    "    print('Starting processing of video', video_id)\n",
    "\n",
    "    video = cv2.VideoCapture(\"Data/\" + datasetName + \"-videos/\" + video_id + \".mp4\")\n",
    "\n",
    "\n",
    "    # First column in the dataset where the video starts:\n",
    "    video_first_dataset_row = videos_list_frames.index(video_id)\n",
    "    \n",
    "    frames = dataset.loadedData[dataset.loadedData['video'] == video_id].sort_values(by=['frame', 'ped_id'], ascending=True)\n",
    "    frames = frames['frame'].tolist()\n",
    "    frames_rev = frames[::-1]\n",
    "    \n",
    "    frames_diff = dataset.loadedData.iloc[diff][dataset.loadedData.iloc[diff]['video'] == video_id]['frame'].tolist()\n",
    "\n",
    "    video_outputs = []\n",
    "\n",
    "    frame_i = 0\n",
    "    ret = True\n",
    "    while ret:\n",
    "\n",
    "        ret, frame = video.read()\n",
    "\n",
    "        if ret:\n",
    "            \n",
    "            frame = frame[...,::-1]\n",
    "            \n",
    "            if frame_i in frames:\n",
    "                \n",
    "                if frame_i in frames_diff:\n",
    "                    \n",
    "                    for pred, gt, data_augm in [[predictions, groundtruth, ''], [predictions2, groundtruth2, 'dataAugmentation4']]:\n",
    "                        \n",
    "                        data_augmentation_name = '' if data_augm == None or data_augm == '' else '_' + data_augm\n",
    "                        \n",
    "                        \n",
    "                        modelName = net + '_' + poseEstimator + '_info=' + str(info) + '_dropout=' + str(dropout) + data_augmentation_name\n",
    "                        modelName = modelName + '_epoch=' + str(num_epochs)\n",
    "                        \n",
    "            \n",
    "                        frame_first_index = frames.index(frame_i)\n",
    "                        frame_last_index = len(frames_rev) - frames_rev.index(frame_i) - 1\n",
    "\n",
    "                        frame_prediction = pred[video_first_dataset_row + frame_first_index:video_first_dataset_row + frame_last_index + 1]\n",
    "                        frame_groundtruth = gt[video_first_dataset_row + frame_first_index:video_first_dataset_row + frame_last_index + 1]\n",
    "\n",
    "                        frame_prediction = [\"Crossing\" if f else \"Not-crossing\" for f in frame_prediction]\n",
    "                        frame_groundtruth = [\"Crossing\" if f else \"Not-crossing\" for f in frame_groundtruth]\n",
    "\n",
    "                        #im_title = \"Prediction: \" + frame_prediction + \"\\nGroundtruth: \" + frame_groundtruth\n",
    "                        im_title = \"Video: \" + video_id\n",
    "                        im_title = im_title + \" - Frame: \" + str(frame_i)\n",
    "                        im_title = im_title + \"\\nPose estimator: \" + poseEstimator #if frame_i == 0 else \"\"\n",
    "                        im_title = im_title + \"\\nClassifier: \" + net + '_info=' + str(info) + '_dropout=' + str(dropout) + data_augmentation_name + '_epoch=' + str(num_epochs)\n",
    "\n",
    "\n",
    "                        fig = dataset.showSkeleton(videoNum=video_id, frameNum=frame_i, showLegend=False, frameImage=frame,\n",
    "                                                   normalizedSkeletons=False, title=im_title, show=False,\n",
    "                                                   predictions=frame_prediction, groundtruths=frame_groundtruth)\n",
    "\n",
    "\n",
    "    #                     canvas = FigureCanvasAgg(fig)\n",
    "    #                     canvas.draw()\n",
    "    #                     frame_result = np.asarray(canvas.buffer_rgba()).astype(np.uint8)\n",
    "\n",
    "    #                     frame_result = Image.fromarray(frame_result)\n",
    "\n",
    "\n",
    "                        fig.savefig(\"Frames_results/\" + datasetName + '/' + poseEstimator + \"/\" + subset + \"/\" + modelName + \"/\" + video_id + \"_\" + str(frame_i) + \".png\",\n",
    "                                    dpi=fig.dpi, bbox_inches='tight')\n",
    "\n",
    "\n",
    "    #                     canvas.get_renderer().clear()\n",
    "                        plt.close(fig)\n",
    "\n",
    "        frame_i = frame_i + 1\n",
    "                \n",
    "    \n",
    "    exported = exported + 1\n",
    "    \n",
    "    print('Exported video:', video_id, ' - Clip', str(exported) + '/' + str(quantity), '\\n')\n",
    "    \n",
    "    video.release()\n",
    "    \n",
    "    if exported == quantity:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
