{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting the JAAD images from videos and showing the crossing prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from torch import from_numpy\n",
    "from torch import cuda\n",
    "from torch import no_grad\n",
    "from torch import optim\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from Code.GNN import *\n",
    "from Code.SkeletonsDataset import *\n",
    "from Code.ModelTrainEvaluate import *\n",
    "\n",
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the skeletons dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = 'test'\n",
    "numberOfClasses = 2\n",
    "info = 2\n",
    "\n",
    "dataset = SkeletonsDataset('Data/' + subset + '_annotations_with_skeletons.csv',\n",
    "                                 normalization='minmax', target='cross', info=info, remove_undetected=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['video_0001',\n",
       " 'video_0003',\n",
       " 'video_0004',\n",
       " 'video_0007',\n",
       " 'video_0008',\n",
       " 'video_0009',\n",
       " 'video_0010',\n",
       " 'video_0011',\n",
       " 'video_0012',\n",
       " 'video_0014',\n",
       " 'video_0017',\n",
       " 'video_0020',\n",
       " 'video_0021',\n",
       " 'video_0023',\n",
       " 'video_0024',\n",
       " 'video_0027',\n",
       " 'video_0028',\n",
       " 'video_0030',\n",
       " 'video_0032',\n",
       " 'video_0035',\n",
       " 'video_0037',\n",
       " 'video_0038',\n",
       " 'video_0039']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos_list = dataset.loadedData['video'].tolist()\n",
    "\n",
    "sorted(list(set(videos_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>frame</th>\n",
       "      <th>skeleton</th>\n",
       "      <th>cross</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>video_0001</td>\n",
       "      <td>0</td>\n",
       "      <td>[[1448.57, 674.503, 0.924437], [1442.74, 698.0...</td>\n",
       "      <td>not-crossing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>video_0001</td>\n",
       "      <td>1</td>\n",
       "      <td>[[1451.47, 674.493, 0.906491], [1445.66, 698.0...</td>\n",
       "      <td>not-crossing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>video_0001</td>\n",
       "      <td>2</td>\n",
       "      <td>[[1451.58, 674.604, 0.856983], [1448.49, 698.0...</td>\n",
       "      <td>not-crossing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>video_0001</td>\n",
       "      <td>3</td>\n",
       "      <td>[[1457.41, 677.444, 0.82119], [1448.66, 698.11...</td>\n",
       "      <td>not-crossing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>video_0001</td>\n",
       "      <td>4</td>\n",
       "      <td>[[1466.12, 677.516, 0.846119], [1451.56, 700.9...</td>\n",
       "      <td>not-crossing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5559</th>\n",
       "      <td>video_0039</td>\n",
       "      <td>355</td>\n",
       "      <td>[[0.0, 0.0, 0.0], [609.777, 795.251, 0.774795]...</td>\n",
       "      <td>crossing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5560</th>\n",
       "      <td>video_0039</td>\n",
       "      <td>356</td>\n",
       "      <td>[[595.029, 771.685, 0.15024], [600.952, 795.13...</td>\n",
       "      <td>crossing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5561</th>\n",
       "      <td>video_0039</td>\n",
       "      <td>357</td>\n",
       "      <td>[[0.0, 0.0, 0.0], [597.887, 795.25, 0.869133],...</td>\n",
       "      <td>crossing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5562</th>\n",
       "      <td>video_0039</td>\n",
       "      <td>358</td>\n",
       "      <td>[[0.0, 0.0, 0.0], [592.049, 792.265, 0.860434]...</td>\n",
       "      <td>crossing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5563</th>\n",
       "      <td>video_0039</td>\n",
       "      <td>359</td>\n",
       "      <td>[[0.0, 0.0, 0.0], [577.545, 795.23, 0.867589],...</td>\n",
       "      <td>crossing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5564 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           video  frame                                           skeleton  \\\n",
       "0     video_0001      0  [[1448.57, 674.503, 0.924437], [1442.74, 698.0...   \n",
       "1     video_0001      1  [[1451.47, 674.493, 0.906491], [1445.66, 698.0...   \n",
       "2     video_0001      2  [[1451.58, 674.604, 0.856983], [1448.49, 698.0...   \n",
       "3     video_0001      3  [[1457.41, 677.444, 0.82119], [1448.66, 698.11...   \n",
       "4     video_0001      4  [[1466.12, 677.516, 0.846119], [1451.56, 700.9...   \n",
       "...          ...    ...                                                ...   \n",
       "5559  video_0039    355  [[0.0, 0.0, 0.0], [609.777, 795.251, 0.774795]...   \n",
       "5560  video_0039    356  [[595.029, 771.685, 0.15024], [600.952, 795.13...   \n",
       "5561  video_0039    357  [[0.0, 0.0, 0.0], [597.887, 795.25, 0.869133],...   \n",
       "5562  video_0039    358  [[0.0, 0.0, 0.0], [592.049, 792.265, 0.860434]...   \n",
       "5563  video_0039    359  [[0.0, 0.0, 0.0], [577.545, 795.23, 0.867589],...   \n",
       "\n",
       "             cross  \n",
       "0     not-crossing  \n",
       "1     not-crossing  \n",
       "2     not-crossing  \n",
       "3     not-crossing  \n",
       "4     not-crossing  \n",
       "...            ...  \n",
       "5559      crossing  \n",
       "5560      crossing  \n",
       "5561      crossing  \n",
       "5562      crossing  \n",
       "5563      crossing  \n",
       "\n",
       "[5564 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.loadedData[['video','frame','skeleton','cross']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes per skeleton: 25\n",
      "Number of features per node: 3\n"
     ]
    }
   ],
   "source": [
    "# First element of the dataset:\n",
    "t0 = dataset[0]\n",
    "\n",
    "# Node features:\n",
    "t1 = t0.x_temporal[0]\n",
    "\n",
    "# Number of nodes:\n",
    "numberOfNodes = t1.shape[0]\n",
    "\n",
    "# Number of dimensions of each node features:\n",
    "embed_dim = t1.shape[1]\n",
    "\n",
    "print('Number of nodes per skeleton:', numberOfNodes)\n",
    "print('Number of features per node:', embed_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SpatialTemporalGNN(embed_dim, numberOfClasses, numberOfNodes)\n",
    "model.load_state_dict(torch.load('exportedModels/Approach_2-3'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the crossing/not-crossing prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, batch_size=500)\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "predictions, groundtruth = predict(model, loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the video and exporting the result as a GIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported video: video_0001\n",
      "Exported video: video_0003\n",
      "Exported video: video_0004\n",
      "Exported video: video_0007\n",
      "Exported video: video_0008\n",
      "Exported video: video_0009\n",
      "Exported video: video_0010\n",
      "Exported video: video_0011\n",
      "Exported video: video_0012\n",
      "Exported video: video_0014\n"
     ]
    }
   ],
   "source": [
    "videos_list = dataset.loadedData['video'].tolist()\n",
    "\n",
    "for video_id in sorted(list(set(videos_list)))[0:10]:\n",
    "\n",
    "    video = cv2.VideoCapture(\"Data/JAAD-videos/\" + subset + \"/\" + video_id + \".mp4\")\n",
    "\n",
    "\n",
    "    # First column in the dataset where the video starts:\n",
    "    video_first_dataset_row = videos_list.index(video_id)\n",
    "\n",
    "\n",
    "    video_outputs = []\n",
    "\n",
    "    frame_i = 0\n",
    "    ret = True\n",
    "    while ret:\n",
    "\n",
    "        ret, frame = video.read()\n",
    "\n",
    "        if ret:\n",
    "\n",
    "            frame_prediction = int(predictions[video_first_dataset_row + frame_i])\n",
    "            frame_groundtruth = int(groundtruth[video_first_dataset_row + frame_i])\n",
    "\n",
    "            frame_prediction = \"Crossing\" if frame_prediction else \"Not-crossing\"\n",
    "            frame_groundtruth = \"Crossing\" if frame_groundtruth else \"Not-crossing\"\n",
    "\n",
    "            im_title = \"Prediction: \" + frame_prediction + \"\\nGroundtruth: \" + frame_groundtruth\n",
    "\n",
    "            try:\n",
    "                \n",
    "                fig = dataset.showSkeleton(videoNum=video_id, frameNum=frame_i, showLegend=False,\n",
    "                                                 frameImage=frame, normalizedSkeletons=False, title=im_title, show=False)\n",
    "            \n",
    "                \n",
    "                canvas = FigureCanvasAgg(fig)\n",
    "                canvas.draw()\n",
    "                frame_result = np.asarray(canvas.buffer_rgba()).astype(np.uint8)\n",
    "\n",
    "                frame_result = Image.fromarray(frame_result)\n",
    "\n",
    "                video_outputs.append(frame_result)\n",
    "\n",
    "                canvas.get_renderer().clear()\n",
    "                plt.close(fig)\n",
    "\n",
    "                frame_i = frame_i + 1\n",
    "                \n",
    "            except:\n",
    "                \n",
    "                ret = False\n",
    "\n",
    "    \n",
    "    # Export the prediction result as a GIF:\n",
    "    video_outputs[0].save(\"Videos_results/\" + subset + \"/\" + video_id + \".gif\", save_all=True,\n",
    "                          append_images=video_outputs[1:], duration=30, loop=0)\n",
    "    \n",
    "    print('Exported video:', video_id)\n",
    "    \n",
    "    video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
